---
title: 'Tweeter sentiment analysis during COVID19 pandemic'
author: "Ivan Kozyryev"
date: "4/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

The goal of my project was to determine whether the overall sentiment of the tweets with COVID19-related hashtags influenced whether the tweet would be retweeted and how many times. My initial hypothesis was that the more negative the tweet is the more retweets it will get because it has potential to stir emotions in many people. During the course of this project as I started to learn more about tweeter, I became more broadly interested in what parameters of the tweet effect the number of retweets. Specifically, I considered the following tweet variables:

1. number of followers
2. number of friends 
3. number of hashtags 
4. number of user mentions 
5. sentiment of the text

While there 90 different variable associated with each tweet and many possibilities for further manipulation of the features, I chose to focus on the five above for two reasons:

* Based on my intuition about social media it seemed likely that those parameters might matter.
* I wanted to have a simpler model that can have interpretable implications about how one can spread positive sentiments and correct information on social media to a wide audience. Or alternatively, understand how *misinformation* related to the disease is effectively spread on social media. 

# Exploratory initial analysis

First let's load all the libraries needed for the analysis of Twitter data. I used [rtweet](https://rtweet.info/) library to interface with the tweeter API. 

```{r message=FALSE}
source('Load_libraries.R')
```

As a first step, let's quickly check what topics are trending on Twitter now. I first get the current trends in the US, then sort all the topics by the tweet volume and look at the top 10 trending topics. 

```{r}
US_trends <- get_trends("United States")

US_trends_sorted <- US_trends %>%
  group_by(trend) %>%
  summarize(tweet_vol = mean(tweet_volume)) %>%
  arrange(desc(tweet_vol))

US_trends_sorted$trend[1:10]
```

As we can see from the list, #COVID__19 is among the top 10 trending topics right now on Twitter which indicates its importance in the social discussion.

# Obtaining the data for tweets

Let's read *original* tweets and see what associated data is available for them. Thus, I have excluded all replies, retweets and quotes. I also only focused on the tweets in English since I am interested in analyzing the sentiment of their text. 

```{r}
covid19_st <- search_tweets("#COVID__19 -filter:retweets -filter:quote -filter:replies",n = 1000, include_rts = FALSE, lang = "en") 
colnames(covid19_st)[1:25]
```
As we can see, there is a lot of parameters associated with each tweet but for now I am interested in only a few of those. There are 90 different parameters but I only displayed 25 for example above. Number of display columns can be modified to see all the available data types for each tweet.
```{r}
covid_twts <- covid19_st[,c("status_id","screen_name","text","retweet_count","followers_count","friends_count","mentions_user_id","hashtags")]
```

## Pre-processing the text for tweets
In order to perform analysis of the text, I first need to clean up the body of the tweet:

* Separate the text from other tweet parameters
* Remove URLs
* Only keep the upper and lower case characters

```{r}
twt_txt <- covid_twts$text # get the tweet text
head(twt_txt)
twt_txt_no_url <- rm_twitter_url(twt_txt)
# head(twt_txt_no_url)
twt_chrs <- gsub("[^A-Za-z]"," ", twt_txt_no_url)
head(twt_chrs)
```

As we can see by comparing the same tweets in the "raw" form and after formatting, we are left only with letters that can be further processed and analyzed. 

## Pre-processing other tweet-related data
The data we read in provides the lists of the hashtags and users mentioned in each tweet, however, I was interested in looking into how the number of hashtags and mentions effects the degree of retweeting which required some initial processing. 

First, lets count the number of mentions and hashtags
```{r}
twts_tidy <- covid_twts %>%
  mutate(text = twt_chrs) %>%
  mutate(mentions = lengths(mentions_user_id)) %>%
  mutate(hashtags = lengths(hashtags))
```
It is important to notice that most of the tweets don't have any mentions with "NA" in place so we need to properly account for that. I first found which tweets don't have any associated mentions of users and then properly corrected the "mentions" count for those entries. 
```{r}
twts_NAinds <- which(is.na(covid_twts$mentions_user_id)) # find which mentions are non-existent
twts_tidy$mentions[twts_NAinds] <- 0 # correct the number of mentions entries for those indeces
```
Unlike for mentions, note that each tweet has at least one hashtag since we specifically searched for #COVID19 tweets to begin with. 

Just for convinience, let's rename the columns of the tweet data set and remove some of the columns that are redundant or will not be useful for our analysis. 
```{r}
twts_tidy <- twts_tidy %>% 
  dplyr::rename(id = status_id, retweets = retweet_count, friends = friends_count, followers = followers_count)
colnames(twts_tidy)
twts_tidy <- twts_tidy %>% 
  dplyr::select(-c(screen_name,mentions_user_id))
```

### Text analysis
In order to study the sentiment of individual tweets we need to unnest tokens (words in this case) and remove stop words that don't carry additional information.
```{r}
twts_clean <- twts_tidy %>%
  unnest_tokens(word,text) %>%
  anti_join(get_stopwords(), by = "word")
```
Let's look at the most common words used in tweets associated with #COVID19
```{r}
common_words <- twts_clean %>%
  count(word) %>%
  arrange(desc(n)) %>%
  top_n(n=25, wt = n)

common_words$word
```
While many of the top words listed have important meaning (like "us" or "people"), there additional words or letter that don't provide any useful information. In the next step, I remove unique stop words that don't add any meaning. 
```{r}
uniq_sw <- data.frame(word = c("s","covid","amp","t", "via", "m", "re", "don", "ve", "q", "gt", "o", "pm"))
# 
twts_clean <- twts_clean %>% 
   anti_join(uniq_sw, by = "word")
```
Notice that I also removed "covid" since all the tweets have it because we specifically searched for #COVID19 and otherwise the wordcloud would be overwhelmed by the "covid" word (hashtag symbol and "19" were removed during the pre-processing step for the text).

# Visualizing the most common words
Let's see which words are the most popular in tweets after we cleanup the text data. 
```{r}
pal <- brewer.pal(8,"Dark2")

twts_clean %>%
  count(word) %>%
  with(wordcloud(word,n,random.order = FALSE, max.words = 100, colors = pal))
```

# Sentiment analysis of the #COVID19 tweets 
From the wordcloud above, we see that some of the most mentioned words are positive in meaning while others are very negative in meaning. We are now ready to perform tweet sentiment analysis to see whether the *overall* tweet sentiment influences the number of retweets (and therefore potentially the influence of a tweet on other users). In the first step I used "afinn" lexicon which assigned a positive or negative score to each word. The reason I decided to use afinn lexicon is that it doesn't purely flag the word as "positive" or "negative" but assigns degrees to how positive or negative each word is.. 

Now lets assign a quantitative score to tweets to determine whether they are positive or negative. But first we need to determine which words from the afinn database appear in the tweets we are processing. 

```{r}
twts_afinn <- twts_clean %>%
  inner_join(get_sentiments("afinn"), by = "word")
```
Lets assign the sentiment score to each unique tweet
```{r}
afinn_sentiment <- twts_afinn %>%
  group_by(id,retweets,followers,friends,hashtags,mentions) %>%
  summarize(score = sum(value)) %>%
  arrange(desc(score))
```
Let's look at some of the most positive tweets to get inspiration for your day (and make sure that our analysis makes sense):
```{r}
covid_twts$text[which(twts_tidy$id == afinn_sentiment$id[1])]
covid_twts$text[which(twts_tidy$id == afinn_sentiment$id[2])]
covid_twts$text[which(twts_tidy$id == afinn_sentiment$id[3])]
```
Those are indeed very positive tweets, so it makes sense that they received high ranking. 

# Regression analysis for binary retweet status

As first step, lets see what factors determine whether the tweet is retweeted at all. 

## Logistic regression

Change the number of retweets into a binary indicator form: "N"(no retweets)/"A"(any retweet)
```{r}
afinn_binary <- afinn_sentiment %>%
  mutate(retwtBi = ifelse(retweets > 0, "A", "N"))
```
Convert the retweet indicator into a ranked factor: N < A
```{r}
afinn_binary <- afinn_binary %>%
  mutate(retwtBi = factor(retwtBi, levels = c("N", "A")))
```
Let's look at the distribution of the tweets into the "None" and "Any" retweet categories. 
```{r}
afinn_binary %>%
  ggplot(aes(retwtBi)) +
  geom_bar() +
  xlab("Retweet category") +
  ggtitle("Distribution of the #COVID19 tweets into retweet categories")
```

As expected, most of the tweets are not reptweeted at all, but a significant portion got retweeted at least ones. In fact we can see how many tweets got retweeted: 
```{r}
afinn_binary %>%
  group_by(retwtBi) %>%
  summarize(n = n())
```

For this given run, looks like **39%** of **10,000** tweets I am analyzing have been retweeted. 

### A brief intro to logistic regression
The probability that a tweet is retweeted is $0<p(A)<1$.We can model such a probability distribution with a logistic function:
$$ \sigma(t)=\frac{1}{1+e^{-t}} $$  
which has the following important properties:

* $\sigma(t)\rightarrow 0$ as $t\rightarrow -\infty$
* $\sigma(t)\rightarrow 1$ as $t\rightarrow \infty$
* $\sigma(t)=1/2$ for $t=0$

Therefore, it seems reasonable to model the probability $p(A)$ as:

$$ p = \frac{\text{exp}(\beta_0+\beta_1x_1+\beta_2x_2+\cdots\beta_kx_k)}{1+\text{exp}(\beta_0+\beta_1x_1+\beta_2x_2+\cdots\beta_kx_k)} $$
which is equivalent to the expression for $\sigma(t)$ above. Therefore, the odds are 

$$ \frac{p}{1-p} = \text{exp}(\beta_0+\beta_1x_1+\beta_2x_2+\cdots\beta_kx_k)$$

but more importantantly $logit(p)$ is $$ \text{log} \left(\frac{p}{1-p}\right)=\beta_0+\beta_1x_1+\beta_2x_2+\cdots\beta_kx_k $$   
is linear in the fitting coefficients $\beta_k$. 
 
### Implementing logistic regression

Before we can we train the logistic regression model, we need to split the dataset into train and test subsets; here I used the 60/40 split ratio.
```{r}
tr <- sample(nrow(afinn_binary),round(nrow(afinn_binary)*0.6))
train <- afinn_binary[tr,]
test <- afinn_binary[-tr,]
```

First, we fit the logit model to the training set to see which parameters are statistically significant:
```{r}
model1LR <- glm(retwtBi ~ followers + friends + score + mentions + hashtags, data = train, family = "binomial")
summary(model1LR)
```

In order to determine how accurate the fitted model is we now apply it to the "test" dataset and compare to the actual values:
```{r}
pred1LR <- predict(model1LR,test, type = "response")

cl1LR <- ifelse(pred1LR > 0.5, "A", "N")
```
Confusion matrix will provide a lot of valuable information on the model peformance:
```{r}
confusionMatrix(factor(cl1LR, levels = c("N","A")),test$retwtBi)
```
From the summary table of logistic regression model (model1LR) we can see that only followers, mentions and hashtags are statistically significant in determining whether the tweet will be retweeted at least once or not. Let's run the second model now only with those parameters
```{r}
model2LR <- glm(retwtBi ~ followers + mentions + hashtags, data = train, family = "binomial")
summary(model2LR)
```
We can see now that all of the variables are statistically significant as expected. 
```{r}
pred2LR <- predict(model2LR,test, type = "response")
cl2LR <- ifelse(pred2LR > 0.5, "A", "N")
confusionMatrix(factor(cl2LR, levels = c("N","A")),test$retwtBi)
```
We can see that accuracy has in fact slightly improved. 

One of the advantages of the ligistic regression is that it's coefficients lend to intuitive interpretation based on the log(odds) discussion above.
```{r}
exp(coef(model2LR)) 
```
We can see that mentions of other users have the largest effect on log-odds. This is something that the author of the tweet can control thus potentially increasing the odd of the tweet being retweeted

## Decision tree for binary retweet indicator

The logit function assumed a linear relationship between the log(odd) and fitting coefficients. Thus it could be instructive to look at some nonlinear models. Let's use the same variables but fit the decision tree instead of logit regression 
```{r}
model1DT <- rpart(retwtBi ~ followers + friends + score + mentions + hashtags, data = train, method = "class")
rpart.plot(model1DT)
```

```{r}
pred1DT <- predict(model1DT,test, type = "class")
cl1DT <- ifelse(pred1TD > 0.5, "A", "N")
confusionMatrix(factor(cl1DT, levels = c("N","A")),test$retwtBi)
```

# let's use the same variables but fit the decision tree instead of logit regression 
model1DT <- rpart(retwtTF ~ followers + friends + score + mentions + hashtags, data = train, method = "class")
rpart.plot(model1DT)
pDT <- predict(model1DT,test, type = "class")

# let's try random forest
model1RF <- train(retwtBi ~ followers + friends + score + mentions + hashtags, data = train, method = "ranger",tuneLength = 5)
pRF <- predict(model1RF,test, type = "class")

# let's plot the ROC curve
caTools::colAUC(cbind(p,pDT), test$retwtTF,plotROC = T)

# area under the ROC curve can be used to compare various models in order to pick the optimal one

cl <- ifelse(p > 0.5, TRUE, FALSE)
table(cl, test$retwtTF)

confusionMatrix(factor(cl),factor(test$retwtTF))

# from the summary table of model1 we can see that only follower, mentions and hashtags are statistically significant in determining 
# whether the tweet will be retweeted at least once or not
# let's run the second model now only with those parameters
model2 <- glm(retwtTF ~ followers + mentions + hashtags, data = train, family = "binomial")
summary(model2)
p <- predict(model2,test, type = "response")
summary(p)
cl <- ifelse(p > 0.5, TRUE, FALSE)
table(cl, test$retwtTF)

# one of the advantages of the ligistic regression is that it's coefficient lend to interpretation 
exp(coef(model2)) # we can see that mentions of other users have the largest effect on log-odds. This is something that
# the author of the tweet can control thus potentially increasing the odd of the tweet being retweeted

# remember that we are looking at the coefficients for log-odds here

# Cross-validation --------------------------------------------------------
# use cross-validation from the caret library
train <- train %>%
  mutate(retwtBi = factor(retwtTF))

test <- test %>%
  mutate(retwtBi = factor(retwtTF))

set.seed(40)

cv_model1 <- train(
  retwtBi ~ followers,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)

cv_model2 <- train(
  retwtBi ~ mentions,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)

cv_model3 <- train(
  retwtBi ~ hashtags,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)

cv_model4 <- train(
  retwtBi ~ followers + mentions + hashtags,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)

# let's comapre the performance of different models now

summary(
  resamples(
    list(
      cv1 = cv_model1,
      cv2 = cv_model2,
      cv3 = cv_model3,
      cv4 = cv_model4
    )
  )
)$statistics$Accuracy

# notice that the accuracy is about the same for all the tested models indicating that adding additional variables that we have does not lead to better predicting power 
# We can try adding more information about the tweet to begin with (remember there are 90 different variables associated with a single tweet we can get)
# however, personally I am interested in seeing which tweets influence many people: i.e. what causes tweet to become "viral" and be retweeted
# thousands of times and potentially have a significant influence on the perception of many people about COVID19. Thus, let's actually divide
# tweets which have been retweet into multiple sub-categories. 



## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
